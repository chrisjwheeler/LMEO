{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "sys.path.append(r'../')\n",
    "\n",
    "from methods import LMEO, Static\n",
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_top5_prompt = f\"Recommend five hotels in London UK. \\n State the name of each hotel only, on a new line each time. Do not start with an intro like 'Here are five hotels in London, UK:'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import anthropic\n",
    "\n",
    "\n",
    "# client = anthropic.Anthropic(\n",
    "#     # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "#     api_key=anthropic_key,\n",
    "# )\n",
    "# message = client.messages.create(\n",
    "#     model=\"claude-3-haiku-20240307\",\n",
    "#     max_tokens=1024, \n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": london_top5_prompt}\n",
    "#     ]\n",
    "# )\n",
    "# print(message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You dont seem to be able to get multiple completions at once. This isnt great will mean you need to loop through. Surley this is slow on everyones end. You can only send 50 requests a minitue. This isnt ideal, but you will be able to get around this. \n",
    "\n",
    "What to do:\n",
    "- Limit to 50 requests per minute. Could just sleep one second between each. \n",
    "- You might as well do the pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import re\n",
    "\n",
    "\n",
    "class ClaudeLMEO(LMEO):\n",
    "    def claude_order_set(self, message_content: str, message_identifier: str = None, model_identifier: str = 'haiku', times: int = 100, num_ranks=5, dump=True):\n",
    "        ''' Generate multiple rank sets. '''\n",
    "\n",
    "        if os.path.exists(fr'.\\pickles\\ranks_claude{model_identifier}_{message_identifier}.pkl'):\n",
    "            print(\"Loading Previously Generated Ranks.\")\n",
    "            with open(fr'.\\pickles\\ranks_claude{model_identifier}_{message_identifier}.pkl', 'rb') as file:\n",
    "                return pickle.load(file)\n",
    "        \n",
    "        message = [{\"role\": \"user\", \"content\": message_content}]\n",
    "        \n",
    "        pattern = r\"\\d+|\\s?-\\s|-\\s|\\s?\\.\\s|\\s|,\"\n",
    "        rank_list = []\n",
    "\n",
    "        try:\n",
    "            for i in range(times):\n",
    "                message = self.anthropic_client.messages.create(\n",
    "                    model=\"claude-3-haiku-20240307\",\n",
    "                    max_tokens=1024, \n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": london_top5_prompt}\n",
    "                            ]\n",
    "                        )\n",
    "                response = message.content[0].text\n",
    "                ranks = response.split(\"\\n\")\n",
    "                print(ranks)\n",
    "\n",
    "                ranks = [re.sub(pattern, \"\", item) for item in ranks]\n",
    "                ranks = [item for item in ranks if item]\n",
    "                \n",
    "                if len(ranks) == num_ranks:\n",
    "                    rank_list.append(ranks)\n",
    "        \n",
    "        except Exception as e:\n",
    "            if len(rank_list) > 30:\n",
    "                with open(fr'.\\pickles\\ranks_claude{model_identifier}_{message_identifier}_aborted.pkl', 'wb') as file:\n",
    "                    pickle.dump(rank_list, file)\n",
    "            raise e\n",
    "        \n",
    "        if dump:\n",
    "            with open(fr'.\\pickles\\ranks_claude{model_identifier}_{message_identifier}.pkl', 'wb') as file:\n",
    "                pickle.dump(rank_list, file)\n",
    "        \n",
    "        return rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Ritz London', 'Mandarin Oriental Hyde Park, London', 'Corinthia Hotel London', 'The Savoy', 'Four Seasons Hotel London at Park Lane']\n",
      "['The Savoy', 'Mandarin Oriental Hyde Park', 'The Ritz London', \"Claridge's\", 'The Connaught']\n",
      "['The Langham, London', \"Claridge's\", 'The Savoy', 'The Ritz London', 'Four Seasons Hotel London at Park Lane']\n",
      "['The Savoy', 'The Ritz London', \"Claridge's\", 'The Langham, London', 'The Connaught']\n",
      "['The Ritz London', 'The Savoy', \"Claridge's\", 'Four Seasons Hotel London at Park Lane', 'The Langham, London']\n",
      "['The Langham, London', \"Claridge's\", 'The Savoy', 'The Ritz London', 'The Connaught']\n",
      "['The Ritz London', 'Mandarin Oriental Hyde Park, London', 'The Savoy', \"Claridge's\", 'Four Seasons Hotel London at Park Lane']\n",
      "['The Savoy', 'The Ritz London', \"Claridge's\", 'The Connaught', 'The Dorchester']\n",
      "['The Savoy', \"Claridge's\", 'The Ritz London', 'The Langham, London', 'Four Seasons Hotel London at Park Lane']\n",
      "['The Ritz London', \"Claridge's\", 'Four Seasons Hotel London at Park Lane', 'The Langham, London', 'The Connaught']\n"
     ]
    }
   ],
   "source": [
    "lm = ClaudeLMEO()\n",
    "trial = lm.claude_order_set(london_top5_prompt, message_identifier='london_top5', times=10, num_ranks=5, dump=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(trial))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
