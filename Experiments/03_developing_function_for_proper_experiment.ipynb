{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "import scipy as sp\n",
    "\n",
    "# sys.path.append(r'.\\LMEO')\n",
    "\n",
    "from pprint import pprint \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_transform(params):\n",
    "    \"\"\"Transform parameters into exp-scale weights.\"\"\"\n",
    "    weights = np.exp(np.asarray(params) - np.mean(params))\n",
    "    return (len(weights) / weights.sum()) * weights\n",
    "\n",
    "def log_transform(weights):\n",
    "    \"\"\"Transform weights into centered log-scale parameters.\"\"\"\n",
    "    params = np.log(weights)\n",
    "    return params - params.mean()\n",
    "\n",
    "import abc\n",
    "class ConvergenceTest(metaclass=abc.ABCMeta):\n",
    "\n",
    "    \"\"\"Abstract base class for convergence tests.\n",
    "\n",
    "    Convergence tests should implement a single function, `__call__`, which\n",
    "    takes a parameter vector and returns a boolean indicating whether or not\n",
    "    the convergence criterion is met.\n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, params, update=True):\n",
    "        \"\"\"Test whether convergence criterion is met.\n",
    "\n",
    "        The parameter `update` controls whether `params` should replace the\n",
    "        previous parameters (i.e., modify the state of the object).\n",
    "        \"\"\"\n",
    "\n",
    "class NormOfDifferenceTest(ConvergenceTest):\n",
    "\n",
    "    \"\"\"Convergence test based on the norm of the difference vector.\n",
    "\n",
    "    This convergence test computes the difference between two successive\n",
    "    parameter vectors, and declares convergence when the norm of this\n",
    "    difference vector (normalized by the number of items) is below `tol`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tol=1e-8, order=1):\n",
    "        self._tol = tol\n",
    "        self._ord = order\n",
    "        self._prev_params = None\n",
    "\n",
    "    def __call__(self, params, update=True):\n",
    "        params = np.asarray(params) - np.mean(params)\n",
    "        if self._prev_params is None:\n",
    "            if update:\n",
    "                self._prev_params = params\n",
    "            return False\n",
    "        dist = np.linalg.norm(self._prev_params - params, ord=self._ord)\n",
    "        if update:\n",
    "            self._prev_params = params\n",
    "        return dist <= self._tol * len(params)\n",
    "\n",
    "\n",
    "def _mm(n_items, data, initial_params, alpha, max_iter, tol, mm_fun):\n",
    "    \"\"\"\n",
    "    Iteratively refine MM estimates until convergence.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If the algorithm does not converge after `max_iter` iterations.\n",
    "    \"\"\"\n",
    "    \n",
    "    if initial_params is None:\n",
    "        params = np.zeros(n_items)\n",
    "    else:\n",
    "        params = initial_params\n",
    "    converged = NormOfDifferenceTest(tol=tol, order=1)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        nums, denoms = mm_fun(n_items, data, params)\n",
    "        params = log_transform((nums + alpha) / (denoms + alpha))\n",
    "        if converged(params):\n",
    "            return params\n",
    "        \n",
    "    raise RuntimeError(\"Did not converge after {} iterations\".format(max_iter))\n",
    "\n",
    "def _mm_rankings(n_items, data, params):\n",
    "    \"\"\"Inner loop of MM algorithm for ranking data.\"\"\"\n",
    "    weights = exp_transform(params)\n",
    "    wins = np.zeros(n_items, dtype=float)\n",
    "    denoms = np.zeros(n_items, dtype=float)\n",
    "    for ranking in data:\n",
    "        sum_ = weights.take(ranking).sum()\n",
    "        for i, winner in enumerate(ranking[:-1]):\n",
    "            wins[winner] += 1\n",
    "            val = 1.0 / sum_\n",
    "            for item in ranking[i:]:\n",
    "                denoms[item] += val\n",
    "            sum_ -= weights[winner]\n",
    "    return wins, denoms\n",
    "\n",
    "\n",
    "def mm_rankings(n_items, data, initial_params=None, alpha=0.0,\n",
    "            max_iter=10000, tol=1e-8):\n",
    "        \"\"\"Compute the ML estimate of model parameters using the MM algorithm.\n",
    "\n",
    "        This function computes the maximum-likelihood (ML) estimate of model\n",
    "        parameters given ranking data (see :ref:`data-rankings`), using the\n",
    "        minorization-maximization (MM) algorithm [Hun04]_, [CD12]_.\n",
    "\n",
    "        If ``alpha > 0``, the function returns the maximum a-posteriori (MAP)\n",
    "        estimate under a (peaked) Dirichlet prior. See :ref:`regularization` for\n",
    "        details.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_items : int\n",
    "            Number of distinct items.\n",
    "        data : list of lists\n",
    "            Ranking data.\n",
    "        initial_params : array_like, optional\n",
    "            Parameters used to initialize the iterative procedure.\n",
    "        alpha : float, optional\n",
    "            Regularization parameter.\n",
    "        max_iter : int, optional\n",
    "            Maximum number of iterations allowed.\n",
    "        tol : float, optional\n",
    "            Maximum L1-norm of the difference between successive iterates to\n",
    "            declare convergence.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params : numpy.ndarray\n",
    "            The ML estimate of model parameters.\n",
    "        \"\"\"\n",
    "        return _mm(n_items, data, initial_params, alpha, max_iter, tol,\n",
    "                _mm_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to convert the ranks to a numbers based of a word list possibly containing lists.\n",
    "## You need other as well.\n",
    "## You should prob return a dict which maps a number to the target word.\n",
    "\n",
    "class ConsitFive:\n",
    "    @staticmethod\n",
    "    def hotel_target_flag(hotel, target_word):\n",
    "            if isinstance(target_word, list):\n",
    "                return any(word in hotel for word in target_word)\n",
    "            else:\n",
    "                return target_word in hotel\n",
    "\n",
    "    def rank_to_num(self, ranks, target_words):\n",
    "        ''' Convert the ranks to a number based on a target word list possibly containing lists.\n",
    "        target_words: Should be chosen so that other is used as comonly on average as each target word.'''\n",
    "        \n",
    "        # Adding category: OTHER to the target words.\n",
    "        inner_target_words = target_words + ['OTHER']\n",
    "\n",
    "        # Coversion dicts.\n",
    "        num_to_id = {i : x[0] if isinstance(x, list) else x for i, x in enumerate(inner_target_words)}\n",
    "        id_to_num = {v : k for k, v in num_to_id.items()}\n",
    "\n",
    "        # Loop through each rank and covert to number.\n",
    "        converted_ranks = []\n",
    "        for rank_instance in ranks:\n",
    "            converted_rank_instance = []\n",
    "            \n",
    "            for hotel in rank_instance:\n",
    "                for target_id in inner_target_words:\n",
    "                    # Will be used to convert the target word to a number.\n",
    "                    single_id = target_id[0] if isinstance(target_id, list) else target_id\n",
    "                    \n",
    "                    if self.hotel_target_flag(hotel, target_id):\n",
    "                        converted_rank_instance.append(id_to_num[single_id])\n",
    "                        break\n",
    "                else: # The hotel is in OTHER category.\n",
    "                    converted_rank_instance.append(id_to_num['OTHER'])\n",
    "            \n",
    "            converted_ranks.append(converted_rank_instance)\n",
    "\n",
    "        return converted_ranks, num_to_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now know how to turn a rankings into a number. \n",
    "# You should create a function which takes a ranking and a target word list and returns a the parameters.\n",
    "# That is just a wrapper. \n",
    "\n",
    "def ranks_to_params(ranks, target_words, **kargs):\n",
    "    cf = ConsitFive()\n",
    "    converted_ranks, num_to_id = cf.rank_to_num(ranks, target_words)\n",
    "    MM_fitted_params = mm_rankings(len(num_to_id), converted_ranks, **kargs)\n",
    "    MM_fitted_params = sorted(zip(MM_fitted_params, num_to_id.values()), key=lambda x: x[0], reverse=True)\n",
    "    return MM_fitted_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988\n",
      "[(2.5870714744923733, 'Ritz'), (0.7136625360414011, 'Langham'), (0.4179767595157995, 'Savoy'), (0.3483472927201855, 'Ned'), (0.301808167249091, 'Shard'), (0.21560685447205374, 'Dorchest'), (-0.17396681601465414, 'OTHER'), (-1.1447293253594197, 'Clarid'), (-3.26577694311683, 'hangri')]\n",
      "[(2.1829326071998616, 'Ritz'), (0.3511280308230571, 'Savoy'), (0.23858368472724123, 'Langham'), (0.13146978179926783, 'Shard'), (-0.02599249236739587, 'Ned'), (-0.06849699509657359, 'Dorchest'), (-0.7056916148250785, 'Clarid'), (-0.796717450548396, 'OTHER'), (-1.3072155517119846, 'hangri')]\n"
     ]
    }
   ],
   "source": [
    "cf = ConsitFive()\n",
    "\n",
    "file_id = 'LondonTop3_1000'\n",
    "\n",
    "with open(fr'.\\pickles\\ranks_{file_id}.pkl', 'rb') as file:\n",
    "    ranks_3 = pickle.load(file)\n",
    "\n",
    "with open(fr'C:\\Users\\chris\\Documents\\LMEO\\LMEO\\Recomendation Research\\pickles\\ranks_London3000.pkl', 'rb') as file:\n",
    "    ranks_5 = pickle.load(file)\n",
    "\n",
    "print(len(ranks_3))\n",
    "\n",
    "london_words = 'Savoy Langham Ritz Ned Clarid hangri Dorchest Shard'.split()\n",
    "\n",
    "print(ranks_to_params(ranks_3, london_words))\n",
    "print(ranks_to_params(ranks_5, london_words, alpha=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now need to write the code to get the pairwise ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_1, hotel_2 = 'Savoy', 'Langham'\n",
    "pairwise_prompt = 'Which hotel do you recommend more: {} or {}. Simply write the name of the hotel and nothing else.'#.format(hotel_1, hotel_2)\n",
    "\n",
    "import openai\n",
    "import anthropic\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class adaptedLMEO1(ConsitFive):\n",
    "    def __init__(self, model: str = \"gpt-3.5-turbo\"):\n",
    "        personal_api_key = os.environ.get('MY_API_KEY')\n",
    "        anthropic_api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "        \n",
    "        self.client = openai.OpenAI(api_key=personal_api_key)\n",
    "        self.anthropic_client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "        self.model = model\n",
    "    \n",
    "    def order_pairwise_preferences(self, pickle_id, pairwise_prompt, proper_hotel_ids, num_time=50, dump=True) -> dict:\n",
    "        ''' Function to order the pairwise preferences. \n",
    "        \n",
    "        Parameters:\n",
    "        pairwise_prompt: str\n",
    "            The prompt to ask the user to compare two hotels.\n",
    "        hotel_name_id_tuple: This is the proper name of the hotel zipped with its id'''\n",
    "\n",
    "        # We want all the permutation of the hotels where they are not (i,i)\n",
    "        hotel_order_permutations = [(hotel_1, hotel_2) for hotel_1 in proper_hotel_ids for hotel_2 in proper_hotel_ids if hotel_1 != hotel_2]\n",
    "        print(hotel_order_permutations)\n",
    "        \n",
    "        all_responses = []\n",
    "        undecided = []\n",
    "\n",
    "        for hotel_1, hotel_2 in hotel_order_permutations:\n",
    "            print(hotel_1, hotel_2)\n",
    "            # Create the pairwise payload.\n",
    "            coresponding_pairwise_prompt = pairwise_prompt.format(hotel_1, hotel_2)\n",
    "            LLM_payload = [{\"role\": \"user\", \"content\": coresponding_pairwise_prompt}]\n",
    "\n",
    "            # Getting the response from the payload\n",
    "            response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=LLM_payload,\n",
    "                    n=num_time,\n",
    "                )\n",
    "            \n",
    "            # Add the responses to the response_dict\n",
    "            for message_obj in response.choices:\n",
    "                preference = message_obj.message.content    \n",
    "\n",
    "                if hotel_1 in preference:\n",
    "                    all_responses.append([hotel_1, hotel_2])\n",
    "                \n",
    "                elif hotel_2 in preference:\n",
    "                    all_responses.append([hotel_2, hotel_1])\n",
    "                \n",
    "                else:\n",
    "                    print(preference)\n",
    "                    undecided.append(preference)\n",
    "\n",
    "        if dump:\n",
    "            with open(fr'.\\pickles\\ranks_{pickle_id}.pkl', 'wb') as file:\n",
    "                pickle.dump(all_responses, file)\n",
    "        \n",
    "        print(undecided)\n",
    "        return all_responses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = adaptedLMEO()\n",
    "\n",
    "proper_hotel_ids = [('\"The Ritz\"', 'Ritz'), ('\"The Savoy\"', 'Savoy'), ('\"The Langham\"', 'Langham')]\n",
    "result = lm.order_pairwise_preferences('Pair_test', pairwise_prompt, proper_hotel_ids, num_time=5, dump=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The Ritz', 'The Savoy'), ('The Ritz', 'The Langham'), ('The Savoy', 'The Ritz'), ('The Savoy', 'The Langham'), ('The Langham', 'The Ritz'), ('The Langham', 'The Savoy')]\n",
      "The Ritz The Savoy\n",
      "The Ritz The Langham\n",
      "The Savoy The Ritz\n",
      "The Savoy The Langham\n",
      "The Langham The Ritz\n",
      "The Langham The Savoy\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "lm = adaptedLMEO1()\n",
    "\n",
    "proper_hotel_ids = ['The Ritz', 'The Savoy', 'The Langham']\n",
    "result = lm.order_pairwise_preferences('Pair_test1', pairwise_prompt, proper_hotel_ids, num_time=5, dump=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[0, 1],\n",
      "  [0, 1],\n",
      "  [0, 1],\n",
      "  [0, 1],\n",
      "  [0, 1],\n",
      "  [0, 2],\n",
      "  [0, 2],\n",
      "  [2, 0],\n",
      "  [2, 0],\n",
      "  [0, 2],\n",
      "  [0, 1],\n",
      "  [0, 1],\n",
      "  [0, 1],\n",
      "  [0, 1],\n",
      "  [0, 1],\n",
      "  [1, 2],\n",
      "  [2, 1],\n",
      "  [1, 2],\n",
      "  [1, 2],\n",
      "  [1, 2],\n",
      "  [0, 2],\n",
      "  [0, 2],\n",
      "  [0, 2],\n",
      "  [0, 2],\n",
      "  [0, 2],\n",
      "  [2, 1],\n",
      "  [1, 2],\n",
      "  [2, 1],\n",
      "  [2, 1],\n",
      "  [2, 1]],\n",
      " {0: 'The Ritz', 1: 'The Savoy', 2: 'The Langham', 3: 'OTHER'})\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "paired = cf.rank_to_num(result, ['The Ritz', 'The Savoy', 'The Langham'])\n",
    "pprint(paired)\n",
    "print(len(paired[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"../\")\n",
    "\n",
    "from methods.SimilarityTests import SimilarityTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 2], [0, 2], [2, 0], [2, 0], [0, 2], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [1, 2], [2, 1], [1, 2], [1, 2], [1, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 2], [2, 1], [1, 2], [2, 1], [2, 1], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(paired[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OTHER'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cf \u001b[38;5;241m=\u001b[39m SimilarityTests()\n\u001b[1;32m----> 2\u001b[0m pprint(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpairwise_ranks_to_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThe Ritz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThe Savoy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThe Langham\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\chris\\Documents\\LMEO\\LMEO\\Experiments\\..\\methods\\SimilarityTests.py:301\u001b[0m, in \u001b[0;36mSimilarityTests.pairwise_ranks_to_params\u001b[1;34m(self, ranks, target_words, **kargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m converted_ranks, num_to_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank_to_num(ranks, target_words)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# We need to drop other from the num_to_id\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mnum_to_id\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOTHER\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    303\u001b[0m MM_fitted_params \u001b[38;5;241m=\u001b[39m mm_pairwise(\u001b[38;5;28mlen\u001b[39m(num_to_id), converted_ranks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkargs) \u001b[38;5;66;03m# Have to minus\u001b[39;00m\n\u001b[0;32m    304\u001b[0m MM_fitted_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mzip\u001b[39m(MM_fitted_params, num_to_id\u001b[38;5;241m.\u001b[39mvalues()), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'OTHER'"
     ]
    }
   ],
   "source": [
    "cf = SimilarityTests()\n",
    "pprint(cf.pairwise_ranks_to_params(result, ['The Ritz', 'The Savoy', 'The Langham'], alpha=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final test which we need to implement is the top1 test. \n",
    "\n",
    "To do:\n",
    "- Simply order based of of prompt and then colate into a list. \n",
    "- Then inside pairwose to params, run the ranks into the rank_to_num then just append the set of indexs to each element at which point you are ready to call the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class top1(ConsitFive):\n",
    "    \n",
    "    def order_top_1(self, pickle_id, prompt, times = 100, dump=True) -> list:\n",
    "        LLM_payload = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "        # Functionality to deal with requests which are greater than the chunk size.\n",
    "\n",
    "        choices_list = []\n",
    "        chunk_size = 128\n",
    "        full_chunks = times // chunk_size\n",
    "        remainder = times % chunk_size\n",
    "\n",
    "        for i in range(full_chunks):\n",
    "            print(f'Ordering batch {i}.')\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=LLM_payload,\n",
    "                n=chunk_size\n",
    "            )\n",
    "            choices_list.extend(response.choices)\n",
    "\n",
    "        if remainder > 0:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=LLM_payload,\n",
    "                n=remainder\n",
    "            )\n",
    "            choices_list.extend(response.choices)\n",
    "\n",
    "        all_responses = [message_obj.message.content for message_obj in choices_list]\n",
    "\n",
    "        if dump:\n",
    "            with open(fr'.\\pickles\\top1_{pickle_id}.pkl', 'wb') as file:\n",
    "                pickle.dump(all_responses, file)\n",
    "\n",
    "        return all_responses\n",
    "    \n",
    "    def top1_ranks_to_params(self, ranks, target_words, **kargs):\n",
    "        ''' Takes a sets of pairwise ranks and converts them to MM parameters.'''\n",
    "        converted_ranks, num_to_id = self.rank_to_num(ranks, target_words, other_flag=True)\n",
    "\n",
    "        index_set = set(range(len(num_to_id)))\n",
    "        formated_ranks = [[rank, index_set] for rank in converted_ranks]\n",
    "        \n",
    "        MM_fitted_params = mm_pairwise(len(num_to_id), formated_ranks, **kargs) # Have to minus\n",
    "        MM_fitted_params = sorted(zip(MM_fitted_params, num_to_id.values()), key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        return MM_fitted_params\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
