{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating function which are needed.\n",
    "\n",
    "- Function to find all which meet condition, first and second but also specifiy the place.\n",
    "- Some form of way to print the frequecy of each. This could just use the itertools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import LMEO, Static\n",
    "lm = LMEO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter function.\n",
    "def filter_perm_in_pos(all_ranks, first_hotel_id, second_hotel_id, pos0 = 0):\n",
    "    '''This filters by a combo i, j or j, i starting at pos0'''\n",
    "    i, j = pos0, pos0 + 1\n",
    "    \n",
    "    def create_condition(hotel_id_obj, place):\n",
    "        if isinstance(hotel_id_obj, list):\n",
    "            return lambda rank: any([hotel_id in rank[place] for hotel_id in hotel_id_obj])\n",
    "        else:\n",
    "            return lambda rank: hotel_id_obj in rank[place]\n",
    "    \n",
    "    first_in_zero = create_condition(first_hotel_id, i)\n",
    "    second_in_one = create_condition(second_hotel_id, j)\n",
    "    \n",
    "    second_in_zero = create_condition(second_hotel_id, i)\n",
    "    first_in_one = create_condition(first_hotel_id, j)\n",
    "    \n",
    "    first_perm_list = []\n",
    "    second_perm_list = []\n",
    "    neither_perm_list = []\n",
    "\n",
    "    for rank in all_ranks:\n",
    "        # This logic could be better but I dont really care.\n",
    "        if first_in_zero(rank) and second_in_one(rank):\n",
    "            first_perm_list.append(rank)\n",
    "        elif second_in_zero(rank) and first_in_one(rank):\n",
    "            second_perm_list.append(rank)\n",
    "        else:\n",
    "            neither_perm_list.append(rank)\n",
    "\n",
    "    return first_perm_list, second_perm_list, neither_perm_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will print the number of occurences for the combo in pos 0\n",
    "import itertools\n",
    "\n",
    "def count_perm_combos(rank_data, target_words, pos0, min = 50):\n",
    "    word_pair_combinations = list(itertools.combinations(target_words, 2))\n",
    "\n",
    "    for word1, word2 in word_pair_combinations:\n",
    "        first, second, _ = filter_perm_in_pos(rank_data, word1, word2, pos0)\n",
    "        if len(first) < min or len(second) < min:\n",
    "            continue\n",
    "        print(word1, word2, len(first), len(second))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Previously Generated Ranks.\n"
     ]
    }
   ],
   "source": [
    "London3000 = lm.order_set('', 'Bristol1001', 0) # lazy because it has the load in it.\n",
    "London_words = 'Savoy Langham Ritz Clarid hangri Dorchest Shard Rose Royal Ned Corin Mandarin'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Experiment. \n",
    "\n",
    "We will first identifiy the combos which are most sensible to test. We will require that both there needs to be over 50 in each position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Savoy Ritz 174 849\n",
      "1\n",
      "Savoy Langham 252 365\n",
      "Langham Dorchest 178 107\n",
      "2\n",
      "Langham Clarid 206 174\n"
     ]
    }
   ],
   "source": [
    "# Identifiying the relevant combos. \n",
    "min = 100\n",
    "for i in range(0, 3):\n",
    "    print(i)\n",
    "    count_perm_combos(London3000, London_words, i, min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are testing whether the next item in the percent dict is distributed in the same way for each of the combos. \n",
    "\n",
    "if pos0 != 0 then we need to consider that the first item cannot appear twice, so we have an aditional assumption that the dist of the zeoth doesnt affect the fourth. \n",
    "\n",
    "To do:\n",
    "Filter as before then get the correct percent dicts and then devise a method to compare the two. There should be a hypothesis test here but you dont know much about them at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the combo Savoy, Ritz in position 0\n",
      "The average difference between the keys is 0.0010600706713778196 with std: 0.044103053876124586 \n",
      "\n",
      "Comparing the combo Savoy, Langham in position 1\n",
      "The average difference between the keys is 0.0005479452054794268 with std: 0.02947337764737162 \n",
      "\n",
      "Comparing the combo Langham, Dorchest in position 1\n",
      "The average difference between the keys is 9.71445146547012e-17 with std: 0.022613727628819136 \n",
      "\n",
      "Comparing the combo Langham, Clarid in position 2\n",
      "The average difference between the keys is 0.0021551724137930527 with std: 0.027671023808658383 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "word_pair_combinations = list(itertools.combinations(London_words, 2))\n",
    "\n",
    "for pos in range(0, 3):\n",
    "    for word1, word2 in word_pair_combinations:\n",
    "        first, second, neither = filter_perm_in_pos(London3000, word1, word2, pos)\n",
    "        \n",
    "        if len(first) <= min or len(second) <= min:\n",
    "            continue\n",
    "                \n",
    "        first = np.column_stack(first)\n",
    "        second = np.column_stack(second)\n",
    "\n",
    "        first_dict = lm.create_percent_dict(first, London_words, 1)\n",
    "        second_dict = lm.create_percent_dict(second, London_words, 1)\n",
    "\n",
    "        # How should you properly compare the percents.\n",
    "        \n",
    "        residuals = [value - second_dict[pos+2].get(key, 0) for key, value in first_dict[pos+2].items()]\n",
    "        mean = np.mean(residuals)\n",
    "        std = np.std(residuals)        \n",
    "\n",
    "        print(f'Comparing the combo {word1}, {word2} in position {pos}')\n",
    "        print(f'The average difference between the keys is {mean} with std: {std} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average difference between the keys is 0.\n",
    "    - So it is not bias as in the two rankings arent bias in one direction for the combo\n",
    "    - The Std is realtively low but not unconsequential. \n",
    "\n",
    "I am unsure if I conclude that the previous order doesnt effect the first choice from here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
